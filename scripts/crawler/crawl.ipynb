{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b433eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/people/people.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc155d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df.iloc[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "def search_and_download_images(query, timeout=30):\n",
    "    folder_name = query.replace(\" \", \"_\")\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    url = f\"https://www.google.com/search?hl=en&tbm=isch&q={query}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=timeout)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        return\n",
    "    except Exception as e:\n",
    "        return\n",
    "\n",
    "    all_images = re.findall(r'https?://[^\\s]*\\.jpg', str(soup))\n",
    "\n",
    "    start_time = time.time()\n",
    "    images = []\n",
    "    for img_url in all_images:\n",
    "        if img_url.endswith('.jpg'):\n",
    "            url_start = img_url.rfind(\"https://\")\n",
    "            url_end = img_url.find(\".jpg\") + 4\n",
    "            img_url_clean = img_url[url_start:url_end]\n",
    "            images.append(img_url_clean)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time >= timeout:\n",
    "            break\n",
    "\n",
    "\n",
    "    for i, img_url in tqdm(enumerate(images, start=1)):\n",
    "        try:\n",
    "            img_data = requests.get(img_url, timeout=3).content\n",
    "            img = Image.open(BytesIO(img_data))\n",
    "            img.save(os.path.join(folder_name, f\"{i}.jpg\"))\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time >= timeout:\n",
    "            break\n",
    "\n",
    "for name in df_sampled['name']:\n",
    "    query = name.replace(\" \", \"+\")\n",
    "    search_and_download_images(query)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
