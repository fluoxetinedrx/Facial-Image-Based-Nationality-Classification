{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import face_recognition\n",
    "from sklearn.cluster import DBSCAN\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "def clean_face_dataset(input_folder, output_folder, min_cluster_ratio=0.1):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    person_name = os.path.basename(input_folder)\n",
    "    person_output_folder = os.path.join(output_folder, person_name)\n",
    "    if not os.path.exists(person_output_folder):\n",
    "        os.makedirs(person_output_folder)\n",
    "    \n",
    "    embeddings = []\n",
    "    file_names = []\n",
    "    \n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    for filename in image_files:\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            face_locations = face_recognition.face_locations(image, model=\"hog\")\n",
    "            \n",
    "            if face_locations:\n",
    "                max_area = 0\n",
    "                max_face_idx = 0\n",
    "                \n",
    "                for i, face_loc in enumerate(face_locations):\n",
    "                    top, right, bottom, left = face_loc\n",
    "                    area = (right - left) * (bottom - top)\n",
    "                    if area > max_area:\n",
    "                        max_area = area\n",
    "                        max_face_idx = i\n",
    "                \n",
    "                face_encodings = face_recognition.face_encodings(\n",
    "                    image, \n",
    "                    [face_locations[max_face_idx]], \n",
    "                    num_jitters=5,\n",
    "                    model=\"large\"\n",
    "                )\n",
    "                \n",
    "                if face_encodings:\n",
    "                    embeddings.append(face_encodings[0])\n",
    "                    file_names.append(filename)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    if len(embeddings) > 0:\n",
    "        embeddings_array = np.array(embeddings)\n",
    "        \n",
    "        best_config = find_best_clustering_config(embeddings_array, person_name)\n",
    "        labels = best_config['labels']\n",
    "        \n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        total_images = len(labels)\n",
    "        \n",
    "        valid_clusters = []\n",
    "        for label, count in zip(unique_labels, counts):\n",
    "            if label == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_ratio = count / total_images\n",
    "            \n",
    "            if cluster_ratio >= min_cluster_ratio:\n",
    "                valid_clusters.append(label)\n",
    "        \n",
    "        valid_count = 0\n",
    "        \n",
    "        for i, label in enumerate(labels):\n",
    "            if label in valid_clusters:\n",
    "                src_path = os.path.join(input_folder, file_names[i])\n",
    "                dst_path = os.path.join(person_output_folder, file_names[i])\n",
    "                shutil.copy(src_path, dst_path)\n",
    "                valid_count += 1\n",
    "        \n",
    "        return valid_count\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def find_best_clustering_config(embeddings_array, person_name):\n",
    "    best_score = float('-inf')\n",
    "    best_eps = 0\n",
    "    best_min_samples = 0\n",
    "    best_labels = None\n",
    "    best_n_clusters = 0\n",
    "\n",
    "    eps_values = [0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "    min_samples_values = [2, 3, 4]\n",
    "\n",
    "    for eps in eps_values:\n",
    "        for min_samples in min_samples_values:\n",
    "            clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"euclidean\").fit(embeddings_array)\n",
    "            labels = clustering.labels_\n",
    "            \n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            n_outliers = np.sum(labels == -1)\n",
    "            outlier_ratio = n_outliers / len(labels)\n",
    "            \n",
    "            score = n_clusters - outlier_ratio\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_eps = eps\n",
    "                best_min_samples = min_samples\n",
    "                best_labels = labels.copy()\n",
    "                best_n_clusters = n_clusters\n",
    "    \n",
    "    return {\n",
    "        'eps': best_eps,\n",
    "        'min_samples': best_min_samples,\n",
    "        'labels': best_labels,\n",
    "        'n_clusters': best_n_clusters\n",
    "    }\n",
    "\n",
    "def zip_folder(folder_path, output_zip):\n",
    "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, os.path.dirname(folder_path))\n",
    "                zipf.write(file_path, arcname)\n",
    "\n",
    "def process_all_folders(base_input_folder, output_folder, min_cluster_ratio=0.1):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    person_folders = [d for d in os.listdir(base_input_folder) \n",
    "                     if os.path.isdir(os.path.join(base_input_folder, d))]\n",
    "    \n",
    "    total_valid_images = 0\n",
    "    \n",
    "    for person_folder in tqdm(person_folders, desc=\"Processing\", ncols=100):\n",
    "        person_path = os.path.join(base_input_folder, person_folder)\n",
    "        \n",
    "        valid_count = clean_face_dataset(\n",
    "            input_folder=person_path,\n",
    "            output_folder=output_folder,\n",
    "            min_cluster_ratio=min_cluster_ratio\n",
    "        )\n",
    "        \n",
    "        total_valid_images += valid_count\n",
    "    \n",
    "    zip_path = output_folder + \".zip\"\n",
    "    zip_folder(output_folder, zip_path)\n",
    "    \n",
    "    return total_valid_images\n",
    "\n",
    "\n",
    "base_input_folder = \"/kaggle/input/train-set/train\"\n",
    "\n",
    "output_folder = \"/kaggle/working/faces_image_cleaned\"\n",
    "\n",
    "min_cluster_ratio = 0.1\n",
    "\n",
    "total_images = process_all_folders(\n",
    "    base_input_folder=base_input_folder,\n",
    "    output_folder=output_folder, \n",
    "    min_cluster_ratio=min_cluster_ratio\n",
    ")\n",
    "\n",
    "print(f\"Tổng số ảnh đã lấy được: {total_images}\")\n",
    "print(f\"Đã nén thành công: {output_folder}.zip\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
